worker_processes  auto;

events {
    worker_connections  4096;    # aumentei para suportar mais conexões
    use epoll;
    multi_accept on;
}

http {
    # Logs
    access_log off;
    error_log /var/log/nginx/error.log warn;

    default_type  application/octet-stream;
    sendfile on;
    tcp_nodelay on;
    tcp_nopush on;
    keepalive_timeout  65;

    # Reuso de conexões com upstream app servers
    upstream backend_apis {
        server 172.25.0.10:9999 max_fails=3 fail_timeout=1s;
        server 172.25.0.11:9999 max_fails=3 fail_timeout=1s;
        keepalive 64;                # permite reusar conexões TCP entre nginx e backends
    }

    # Proxy defaults para reduzir repetição
    proxy_connect_timeout  200ms;   # tempo para abrir conexão com backend
    proxy_send_timeout     1s;      # tempo máximo para enviar request ao backend
    proxy_read_timeout     1s;      # tempo máximo para ler resposta do backend
    proxy_buffering        off;     # desligado para evitar buffer em disco (útil para low-latency APIs); ligue se precisar de cache/throughput
    proxy_request_buffering off;    # envia o body direto ao backend (não bufferiza) — bom para streaming POSTs
    proxy_http_version     1.1;
    proxy_set_header       Connection "";   # permite reuso de keepalive (não força "close")
    proxy_set_header       Host $host;
    proxy_set_header       X-Real-IP $remote_addr;
    proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header       X-Forwarded-Proto $scheme;

    # Ajuste de buffers; valores conservadores para respostas pequenas (JSON)
    proxy_buffer_size          8k;
    proxy_buffers              4 8k;
    proxy_busy_buffers_size    16k;
    proxy_max_temp_file_size   0;    # evita escrita em disco quando proxy_buffering on; 0 = desabilita

    # Gzip se fizer sentido (descomente se quiser)
    # gzip on;
    # gzip_types application/json text/plain;

    server {
        # use reuseport para melhor escalonamento com worker_processes auto
        listen 9999 reuseport backlog=1024;

        location / {
            proxy_pass         http://backend_apis;
            # Herda as diretivas acima (proxy_connect_timeout, proxy_read_timeout, etc.)
            proxy_next_upstream error timeout http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 2;
        }

        # endpoint para métricas simples (se desejar)
        location /nginx_status {
            stub_status on;
            allow 127.0.0.1;
            deny all;
        }
    }
}
