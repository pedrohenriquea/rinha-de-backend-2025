x-api-conf: &api-conf
  image: ghcr.io/100f/rinha-backend-2025:1.0.5
  environment:
    CONSUMERS_AMOUNT: 450
    CONSUMERS_CONCURRENCY_FACTOR: 8192
    PAYMENT_PROCESSOR_RESPONSE_TIMEOUT_MS: 4000
    PIPELINE_POLLING_MS: 80
    CONNECTION_ACQUIRE_TIMEOUT_MS: 5000
    MAX_CONNECTIONS: 3000
    JAVA_OPTS: >
      -XX:+UseG1GC
      -XX:+AlwaysPreTouch
      -XX:+UseNUMA
      -XX:+UseFastAccessorMethods
      -XX:+UseStringCache
      -XX:+OptimizeStringConcat
      -Dio.netty.allocator.type=pooled
      -Dreactor.schedulers.defaultBoundedElasticQueueSize=200000
      -Dreactor.schedulers.defaultBoundedElasticOnVirtualThreads=true
      -Dreactor.schedulers.defaultBoundedElasticSize=1024
  healthcheck:
    test: ["CMD", "wget", "--spider", "-q", "http://localhost:8054/health"]
    interval: 2s
    timeout: 5s
    retries: 5
  networks:
    - backend
    - payment-processor
  depends_on:
    key-db:
      condition: service_healthy
  deploy:
    resources:
      limits:
        cpus: "0.45"
        memory: "125MB"

services:
  key-db:
    image: eqalpha/keydb:latest
    container_name: key-db
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "keydb-cli", "ping"]
      interval: 2s
      timeout: 5s
      retries: 5
    networks:
      - backend
    deploy:
      resources:
        limits:
          cpus: "0.3"
          memory: "20MB"

  api1:
    <<: *api-conf
    container_name: api1

  api2:
    <<: *api-conf
    container_name: api2

  haproxy:
    image: haproxy:3.3-dev
    container_name: lb
    ports:
      - "9999:9999"
    networks:
      - backend
    depends_on:
      api1:
        condition: service_healthy
      api2:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "0.3"
          memory: "80MB"
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro

networks:
  backend:
    driver: bridge
  payment-processor:
    external: true